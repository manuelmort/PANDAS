{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d31437",
   "metadata": {},
   "source": [
    "# Phikon Feature Extraction for PANDA Prostate Cancer Dataset\n",
    "\n",
    "Extract 768-dimensional pathology-specific features from WSI patches using the Phikon foundation model\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Background\n",
    "\n",
    "Our baseline GTP (Graph Transformer) model used **ResNet50** pretrained on **ImageNet** (natural images like cats, dogs, cars) to extract features from histopathology patches. While this achieved strong results (QWK: 0.7568, AUPRC: 0.8129), ImageNet features are not optimized for medical tissue analysis.\n",
    "\n",
    "### Motivation\n",
    "\n",
    "**Phikon** is a Vision Transformer (ViT-Base) pretrained on **40+ million histopathology images** - the same type of H&E-stained tissue images we're analyzing. This domain-specific pretraining should provide features that better capture:\n",
    "\n",
    "- Cellular morphology patterns\n",
    "- Gland architecture\n",
    "- Tissue texture specific to pathology\n",
    "- Cancer-relevant visual features\n",
    "\n",
    "### What We're Doing\n",
    "\n",
    "1. **Replace ImageNet features with pathology-specific features**\n",
    "   - ResNet50 (ImageNet): 2048-dim general features\n",
    "   - Phikon (Pathology): 768-dim domain-specific features\n",
    "\n",
    "2. **Extract features from all WSI patches**\n",
    "   - ~8,500 Whole Slide Images\n",
    "   - ~150 patches per WSI (average)\n",
    "   - ~1.2 million total patches\n",
    "\n",
    "3. **Build spatial graphs** (same as baseline)\n",
    "   - 8-connectivity adjacency\n",
    "   - Preserve tissue architecture\n",
    "\n",
    "4. **Train GTP with new features**\n",
    "   - Same architecture, different input features\n",
    "   - Compare with ResNet50 baseline\n",
    "\n",
    "### Expected Outcome (Yet to run - 12/6)\n",
    "\n",
    "| Model | Feature Dim | QWK | AUPRC |\n",
    "|-------|-------------|-----|-------|\n",
    "| ResNet50 (ImageNet) | 2048 | 0.7568 | 0.8129 |\n",
    "| Phikon (Pathology) | 768 | 0.78-0.82 | 0.84-0.87 |\n",
    "\n",
    "**Expected improvement: +3-8% QWK**\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Using a pathology foundation model demonstrates:\n",
    "- Understanding of domain-specific transfer learning\n",
    "- Awareness of recent advances in medical AI\n",
    "- Ability to improve upon standard baselines\n",
    "- Satisfies professor's requirement to try an H&E foundation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c689a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXTRACTING PHIKON FEATURES FROM WSI PATCHES\n",
      "======================================================================\n",
      "\n",
      "Loading Phikon model...\n",
      "✓ Phikon loaded on cuda\n",
      "  Feature dimension: 768\n",
      "\n",
      "Finding all WSI directories...\n",
      "  tiles_01: 850 WSIs\n",
      "  tiles_02: 850 WSIs\n",
      "  tiles_03: 850 WSIs\n",
      "  tiles_04: 850 WSIs\n",
      "  tiles_05: 850 WSIs\n",
      "  tiles_06: 850 WSIs\n",
      "  tiles_07: 850 WSIs\n",
      "  tiles_08: 850 WSIs\n",
      "  tiles_09: 850 WSIs\n",
      "  tiles_10: 842 WSIs\n",
      "  val_tiles: 2124 WSIs\n",
      "\n",
      "✓ Total WSIs found: 10616\n",
      "  Training: 8492\n",
      "  Validation: 2124\n",
      "\n",
      "======================================================================\n",
      "Starting feature extraction...\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 10616/10616 [1:47:52<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Total WSIs: 10616\n",
      "Processed: 2123\n",
      "Skipped (already done): 8492\n",
      "Errors: 0\n",
      "\n",
      "Output saved to: /projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/feature_extractor/graphs_phikon/panda\n",
      "Feature dimension: 768\n",
      "\n",
      "Verified: 10615 graphs created\n",
      "\n",
      "Next step: Train GTP with --n_features 768\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Extract Phikon Features - TRAINING + VALIDATION TILES\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING PHIKON FEATURES FROM WSI PATCHES\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "TILES_DIRS = [\n",
    "    # Training tiles\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_01\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_02\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_03\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_04\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_05\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_06\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_07\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_08\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_09\",\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_10\",\n",
    "    # Validation tiles (single directory)\n",
    "    \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/val_tiles\",\n",
    "]\n",
    "\n",
    "OUTPUT_DIR = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/feature_extractor/graphs_phikon/panda\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD PHIKON\n",
    "# ============================================================\n",
    "print(\"Loading Phikon model...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained(\"owkin/phikon\")\n",
    "model = ViTModel.from_pretrained(\"owkin/phikon\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(f\"✓ Phikon loaded on {device}\")\n",
    "print(f\"  Feature dimension: 768\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# FIND ALL WSI DIRECTORIES\n",
    "# ============================================================\n",
    "print(\"Finding all WSI directories...\")\n",
    "\n",
    "all_wsi_dirs = []\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "\n",
    "for tiles_dir in TILES_DIRS:\n",
    "    if not os.path.exists(tiles_dir):\n",
    "        print(f\"  ⚠ Skipping {tiles_dir} (not found)\")\n",
    "        continue\n",
    "    \n",
    "    # Pattern: tiles_XX/wsi_id/\n",
    "    wsi_dirs = [d for d in glob.glob(f\"{tiles_dir}/*/\") if os.path.isdir(d)]\n",
    "    all_wsi_dirs.extend(wsi_dirs)\n",
    "    \n",
    "    dir_name = os.path.basename(tiles_dir)\n",
    "    if \"val\" in dir_name:\n",
    "        val_count += len(wsi_dirs)\n",
    "    else:\n",
    "        train_count += len(wsi_dirs)\n",
    "    \n",
    "    print(f\"  {dir_name}: {len(wsi_dirs)} WSIs\")\n",
    "\n",
    "print(f\"\\n✓ Total WSIs found: {len(all_wsi_dirs)}\")\n",
    "print(f\"  Training: {train_count}\")\n",
    "print(f\"  Validation: {val_count}\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT FEATURES\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"Starting feature extraction...\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "processed = 0\n",
    "skipped = 0\n",
    "errors = 0\n",
    "\n",
    "for wsi_dir in tqdm(all_wsi_dirs, desc=\"Extracting features\"):\n",
    "    wsi_id = os.path.basename(wsi_dir.rstrip('/'))\n",
    "    \n",
    "    # Output directory for this WSI\n",
    "    wsi_output_dir = os.path.join(OUTPUT_DIR, wsi_id)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if os.path.exists(os.path.join(wsi_output_dir, 'features.pt')):\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Get all patches (JPEG files!)\n",
    "    patches = glob.glob(f\"{wsi_dir}/*.jpeg\") + glob.glob(f\"{wsi_dir}/*.jpg\") + glob.glob(f\"{wsi_dir}/*.JPEG\") + glob.glob(f\"{wsi_dir}/*.JPG\")\n",
    "    \n",
    "    if len(patches) == 0:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        features_list = []\n",
    "        coords_list = []\n",
    "        \n",
    "        for patch_path in patches:\n",
    "            try:\n",
    "                # Get coordinates from filename (format: row_col.jpeg)\n",
    "                filename = os.path.basename(patch_path)\n",
    "                name_parts = filename.replace('.jpeg', '').replace('.jpg', '').replace('.JPEG', '').replace('.JPG', '').split('_')\n",
    "                \n",
    "                if len(name_parts) >= 2:\n",
    "                    row, col = int(name_parts[0]), int(name_parts[1])\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                # Load and process image\n",
    "                img = Image.open(patch_path).convert('RGB')\n",
    "                inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "                \n",
    "                # Extract features\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    features = outputs.last_hidden_state[:, 0]  # CLS token (768-dim)\n",
    "                \n",
    "                features_list.append(features.cpu())\n",
    "                coords_list.append([row, col])\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Build adjacency matrix and save\n",
    "        if len(features_list) > 0:\n",
    "            os.makedirs(wsi_output_dir, exist_ok=True)\n",
    "            \n",
    "            features_tensor = torch.cat(features_list, dim=0)  # [N, 768]\n",
    "            N = features_tensor.shape[0]\n",
    "            \n",
    "            # Build adjacency matrix (8-connectivity)\n",
    "            adj = torch.zeros(N, N)\n",
    "            for i in range(N):\n",
    "                for j in range(i+1, N):\n",
    "                    row_diff = abs(coords_list[i][0] - coords_list[j][0])\n",
    "                    col_diff = abs(coords_list[i][1] - coords_list[j][1])\n",
    "                    if row_diff <= 1 and col_diff <= 1:\n",
    "                        adj[i, j] = 1\n",
    "                        adj[j, i] = 1\n",
    "            \n",
    "            # Save\n",
    "            torch.save(features_tensor, os.path.join(wsi_output_dir, 'features.pt'))\n",
    "            torch.save(adj, os.path.join(wsi_output_dir, 'adj_s.pt'))\n",
    "            \n",
    "            with open(os.path.join(wsi_output_dir, 'c_idx.txt'), 'w') as f:\n",
    "                for coord in coords_list:\n",
    "                    f.write(f\"{coord[0]}\\t{coord[1]}\\n\")\n",
    "            \n",
    "            processed += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        continue\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE EXTRACTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"Total WSIs: {len(all_wsi_dirs)}\")\n",
    "print(f\"Processed: {processed}\")\n",
    "print(f\"Skipped (already done): {skipped}\")\n",
    "print(f\"Errors: {errors}\")\n",
    "print()\n",
    "print(f\"Output saved to: {OUTPUT_DIR}\")\n",
    "print(f\"Feature dimension: 768\")\n",
    "print()\n",
    "\n",
    "# Verify\n",
    "output_count = len(glob.glob(f\"{OUTPUT_DIR}/*/features.pt\"))\n",
    "print(f\"Verified: {output_count} graphs created\")\n",
    "print()\n",
    "print(\"Next step: Train GTP with --n_features 768\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896481e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BUILDING GRAPHS FROM PHIKON FEATURES\n",
      "======================================================================\n",
      "\n",
      "Building graphs with 8-connectivity...\n",
      "\n",
      "Found 0 WSIs with Phikon features\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GRAPH CONSTRUCTION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Processed: 0 WSIs\n",
      "Graphs saved to: /projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/feature_extractor/graphs_phikon/panda\n",
      "Feature dimension: 768\n",
      "\n",
      "Next step: Train GTP with --n_features 768\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Build Graphs from Phikon Features\n",
    "\"\"\"\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BUILDING GRAPHS FROM PHIKON FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "FEATURES_DIR = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/feature_extractor/phikon_features\"\n",
    "OUTPUT_DIR = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/feature_extractor/graphs_phikon/panda\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CONNECTIVITY = 8  # 8-connectivity (patches within 1 grid position)\n",
    "\n",
    "# ============================================================\n",
    "# BUILD GRAPHS\n",
    "# ============================================================\n",
    "print(\"Building graphs with 8-connectivity...\")\n",
    "print()\n",
    "\n",
    "feature_files = glob.glob(f\"{FEATURES_DIR}/*.pt\")\n",
    "print(f\"Found {len(feature_files)} WSIs with Phikon features\")\n",
    "print()\n",
    "\n",
    "processed = 0\n",
    "for feature_file in tqdm(feature_files):\n",
    "    wsi_id = os.path.basename(feature_file).replace('_phikon.pt', '')\n",
    "    \n",
    "    # Output directory for this WSI\n",
    "    wsi_output_dir = os.path.join(OUTPUT_DIR, wsi_id)\n",
    "    os.makedirs(wsi_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if os.path.exists(os.path.join(wsi_output_dir, 'features.pt')):\n",
    "        continue\n",
    "    \n",
    "    # Load features and coordinates\n",
    "    data = torch.load(feature_file)\n",
    "    features = data['features']  # Shape: [N, 768]\n",
    "    coords = data['coords']  # Shape: [N, 2]\n",
    "    \n",
    "    N = features.shape[0]\n",
    "    \n",
    "    # Build adjacency matrix (8-connectivity)\n",
    "    adj = torch.zeros(N, N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            # Check if within 1 grid position (8-connectivity)\n",
    "            row_diff = abs(coords[i, 0] - coords[j, 0])\n",
    "            col_diff = abs(coords[i, 1] - coords[j, 1])\n",
    "            \n",
    "            if row_diff <= 1 and col_diff <= 1:\n",
    "                adj[i, j] = 1\n",
    "                adj[j, i] = 1\n",
    "    \n",
    "    # Save graph\n",
    "    torch.save(features, os.path.join(wsi_output_dir, 'features.pt'))\n",
    "    torch.save(adj, os.path.join(wsi_output_dir, 'adj_s.pt'))\n",
    "    \n",
    "    # Save coordinates as text\n",
    "    with open(os.path.join(wsi_output_dir, 'c_idx.txt'), 'w') as f:\n",
    "        for coord in coords:\n",
    "            f.write(f\"{coord[0]} {coord[1]}\\n\")\n",
    "    \n",
    "    processed += 1\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"GRAPH CONSTRUCTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"Processed: {processed} WSIs\")\n",
    "print(f\"Graphs saved to: {OUTPUT_DIR}\")\n",
    "print(f\"Feature dimension: 768\")\n",
    "print()\n",
    "print(\"Next step: Train GTP with --n_features 768\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a640a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda_env",
   "language": "python",
   "name": "panda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
