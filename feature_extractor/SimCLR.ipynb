{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b07413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 28 18:12:15 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:17:00.0 Off |                    0 |\n",
      "|  0%   32C    P8             21W /  300W |       0MiB /  46068MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A40                     On  |   00000000:65:00.0 Off |                    0 |\n",
      "|  0%   32C    P8             21W /  300W |       0MiB /  46068MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A40                     On  |   00000000:CA:00.0 Off |                    0 |\n",
      "|  0%   31C    P8             21W /  300W |       0MiB /  46068MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A40                     On  |   00000000:E3:00.0 Off |                    0 |\n",
      "|  0%   32C    P8             22W /  300W |       0MiB /  46068MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d537cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b6415",
   "metadata": {},
   "source": [
    "### Training SimCLR using ResNet backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fb2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "Running on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/ec500kb/projects/Project_1_Team_1/panda_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/projectnb/ec500kb/projects/Project_1_Team_1/panda_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/projectnb/ec500kb/projects/Project_1_Team_1/panda_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractor: resnet18\n",
      "✓ No SimCLR checkpoint found. Using ImageNet pretrained ResNet backbone.\n",
      "\n",
      "======================================================================\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "Total epochs:        5\n",
      "Steps per epoch:     860\n",
      "Total steps:         4300\n",
      "Batch size:          128\n",
      "Log every:           100 steps\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "EPOCH [1/5]\n",
      "======================================================================\n",
      "[Epoch 1/5] Step 0/4300 (0.0%) | Loss: 5.410 | ETA: 517.6 min\n",
      "[Epoch 1/5] Step 100/4300 (2.3%) | Loss: 3.730 | ETA: 49.1 min\n",
      "[Epoch 1/5] Step 200/4300 (4.7%) | Loss: 3.670 | ETA: 46.1 min\n",
      "[Epoch 1/5] Step 300/4300 (7.0%) | Loss: 3.686 | ETA: 44.2 min\n",
      "[Epoch 1/5] Step 400/4300 (9.3%) | Loss: 3.648 | ETA: 42.7 min\n",
      "[Epoch 1/5] Step 500/4300 (11.6%) | Loss: 3.667 | ETA: 41.4 min\n",
      "[Epoch 1/5] Step 600/4300 (14.0%) | Loss: 3.646 | ETA: 40.1 min\n",
      "[Epoch 1/5] Step 700/4300 (16.3%) | Loss: 3.693 | ETA: 38.9 min\n",
      "[Epoch 1/5] Step 800/4300 (18.6%) | Loss: 3.656 | ETA: 37.8 min\n",
      "\n",
      "Epoch 1 completed in 9.28 minutes\n",
      "[1/5] Validation Loss: 3.663\n",
      "✓ Model saved (best validation loss)\n",
      "\n",
      "======================================================================\n",
      "EPOCH [2/5]\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/ec500kb/projects/Project_1_Team_1/panda_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:1090: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  _warn_get_lr_called_within_step(self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/5] Step 900/4300 (20.9%) | Loss: 3.635 | ETA: 40.9 min\n",
      "[Epoch 2/5] Step 1000/4300 (23.3%) | Loss: 3.630 | ETA: 39.3 min\n",
      "[Epoch 2/5] Step 1100/4300 (25.6%) | Loss: 3.675 | ETA: 37.7 min\n",
      "[Epoch 2/5] Step 1200/4300 (27.9%) | Loss: 3.671 | ETA: 36.3 min\n",
      "[Epoch 2/5] Step 1300/4300 (30.2%) | Loss: 3.634 | ETA: 34.9 min\n",
      "[Epoch 2/5] Step 1400/4300 (32.6%) | Loss: 3.651 | ETA: 33.5 min\n",
      "[Epoch 2/5] Step 1500/4300 (34.9%) | Loss: 3.641 | ETA: 32.2 min\n",
      "[Epoch 2/5] Step 1600/4300 (37.2%) | Loss: 3.651 | ETA: 30.9 min\n",
      "[Epoch 2/5] Step 1700/4300 (39.5%) | Loss: 3.628 | ETA: 29.6 min\n",
      "\n",
      "Epoch 2 completed in 9.27 minutes\n",
      "\n",
      "======================================================================\n",
      "EPOCH [3/5]\n",
      "======================================================================\n",
      "[Epoch 3/5] Step 1800/4300 (41.9%) | Loss: 3.684 | ETA: 28.5 min\n",
      "[Epoch 3/5] Step 1900/4300 (44.2%) | Loss: 3.619 | ETA: 27.3 min\n",
      "[Epoch 3/5] Step 2000/4300 (46.5%) | Loss: 3.628 | ETA: 26.1 min\n",
      "[Epoch 3/5] Step 2100/4300 (48.8%) | Loss: 3.642 | ETA: 25.0 min\n",
      "[Epoch 3/5] Step 2200/4300 (51.2%) | Loss: 3.619 | ETA: 23.8 min\n",
      "[Epoch 3/5] Step 2300/4300 (53.5%) | Loss: 3.617 | ETA: 22.6 min\n",
      "[Epoch 3/5] Step 2400/4300 (55.8%) | Loss: 3.627 | ETA: 21.4 min\n",
      "[Epoch 3/5] Step 2500/4300 (58.1%) | Loss: 3.666 | ETA: 20.3 min\n",
      "\n",
      "Epoch 3 completed in 9.46 minutes\n",
      "\n",
      "======================================================================\n",
      "EPOCH [4/5]\n",
      "======================================================================\n",
      "[Epoch 4/5] Step 2600/4300 (60.5%) | Loss: 3.627 | ETA: 19.2 min\n",
      "[Epoch 4/5] Step 2700/4300 (62.8%) | Loss: 3.627 | ETA: 18.0 min\n",
      "[Epoch 4/5] Step 2800/4300 (65.1%) | Loss: 3.623 | ETA: 16.9 min\n",
      "[Epoch 4/5] Step 2900/4300 (67.4%) | Loss: 3.622 | ETA: 15.7 min\n",
      "[Epoch 4/5] Step 3000/4300 (69.8%) | Loss: 3.645 | ETA: 14.6 min\n",
      "[Epoch 4/5] Step 3100/4300 (72.1%) | Loss: 3.656 | ETA: 13.4 min\n",
      "[Epoch 4/5] Step 3200/4300 (74.4%) | Loss: 3.617 | ETA: 12.3 min\n",
      "[Epoch 4/5] Step 3300/4300 (76.7%) | Loss: 3.628 | ETA: 11.2 min\n",
      "[Epoch 4/5] Step 3400/4300 (79.1%) | Loss: 3.662 | ETA: 10.0 min\n",
      "\n",
      "Epoch 4 completed in 9.25 minutes\n",
      "\n",
      "======================================================================\n",
      "EPOCH [5/5]\n",
      "======================================================================\n",
      "[Epoch 5/5] Step 3500/4300 (81.4%) | Loss: 3.654 | ETA: 8.9 min\n",
      "[Epoch 5/5] Step 3600/4300 (83.7%) | Loss: 3.621 | ETA: 7.8 min\n",
      "[Epoch 5/5] Step 3700/4300 (86.0%) | Loss: 3.634 | ETA: 6.7 min\n",
      "[Epoch 5/5] Step 3800/4300 (88.4%) | Loss: 3.608 | ETA: 5.6 min\n",
      "[Epoch 5/5] Step 3900/4300 (90.7%) | Loss: 3.621 | ETA: 4.4 min\n",
      "[Epoch 5/5] Step 4000/4300 (93.0%) | Loss: 3.629 | ETA: 3.3 min\n",
      "[Epoch 5/5] Step 4100/4300 (95.3%) | Loss: 3.626 | ETA: 2.2 min\n",
      "[Epoch 5/5] Step 4200/4300 (97.7%) | Loss: 3.631 | ETA: 1.1 min\n",
      "\n",
      "Epoch 5 completed in 9.22 minutes\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETE\n",
      "======================================================================\n",
      "Total training time: 47.52 minutes (0.79 hours)\n",
      "Final loss: 3.609\n",
      "Best validation loss: 3.663\n",
      "Model saved to: runs/Nov29_15-00-34_scc-214/checkpoints\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from simclr import SimCLR\n",
    "import yaml\n",
    "from data_aug.dataset_wrapper import DataSetWrapper\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "def main():\n",
    "    # Filter out ALL Jupyter kernel arguments\n",
    "    sys.argv = [sys.argv[0]]  # Keep only the script name\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--magnification', type=str, default='20x')\n",
    "    args = parser.parse_args()\n",
    "    config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "    \n",
    "    # Override GPU settings for single GPU\n",
    "    config['n_gpu'] = 2\n",
    "    config['gpu_ids'] = \"[0,1]\"  # When you set CUDA_VISIBLE_DEVICES='2,3', they become 0 and 1\n",
    "   \n",
    "    dataset = DataSetWrapper(config['batch_size'], **config['dataset'])\n",
    "    simclr = SimCLR(dataset, config)\n",
    "    simclr.train()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9d20a",
   "metadata": {},
   "source": [
    "Test Model with weights using 10 random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489ef519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SIMCLR MODEL TEST\n",
      "======================================================================\n",
      "Loading trained SimCLR model...\n",
      "Feature extractor: resnet18\n",
      "✓ Model loaded from runs/Nov29_15-00-34_scc-214/checkpoints/model.pth\n",
      "\n",
      "Finding test patches in /projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_03...\n",
      "✓ Found 120115 total patches\n",
      "✓ Testing on 10 random patches\n",
      "\n",
      "Extracting features...\n",
      "----------------------------------------------------------------------\n",
      "[1/10] 26_13.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      23.271\n",
      "  Feature mean:      0.519 ± 0.888\n",
      "\n",
      "[2/10] 6_8.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      21.493\n",
      "  Feature mean:      0.573 ± 0.757\n",
      "\n",
      "[3/10] 7_4.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      24.652\n",
      "  Feature mean:      0.738 ± 0.802\n",
      "\n",
      "[4/10] 6_10.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      21.034\n",
      "  Feature mean:      0.545 ± 0.753\n",
      "\n",
      "[5/10] 21_16.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      31.220\n",
      "  Feature mean:      0.723 ± 1.175\n",
      "\n",
      "[6/10] 38_10.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      32.653\n",
      "  Feature mean:      1.030 ± 1.010\n",
      "\n",
      "[7/10] 21_18.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      30.615\n",
      "  Feature mean:      0.881 ± 1.027\n",
      "\n",
      "[8/10] 35_23.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      22.589\n",
      "  Feature mean:      0.627 ± 0.777\n",
      "\n",
      "[9/10] 12_10.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      21.224\n",
      "  Feature mean:      0.577 ± 0.740\n",
      "\n",
      "[10/10] 7_58.jpeg\n",
      "  Features shape:    (512,)\n",
      "  Projections shape: (512,)\n",
      "  Feature norm:      25.891\n",
      "  Feature mean:      0.636 ± 0.951\n",
      "\n",
      "======================================================================\n",
      "FEATURE ANALYSIS\n",
      "======================================================================\n",
      "Features shape:    (10, 512)\n",
      "Projections shape: (10, 512)\n",
      "\n",
      "Feature statistics:\n",
      "  Mean:     0.6850\n",
      "  Std:      0.9122\n",
      "  Min:      0.0000\n",
      "  Max:      7.3208\n",
      "\n",
      "Feature diversity check:\n",
      "  Pairwise cosine similarity:\n",
      "    Mean: 0.539\n",
      "    Std:  0.178\n",
      "    Min:  0.163\n",
      "    Max:  0.941\n",
      "\n",
      "======================================================================\n",
      "INTERPRETATION\n",
      "======================================================================\n",
      "✓ OK: Features have moderate diversity\n",
      "  → Model provides useful representations\n",
      "\n",
      "Model is ready to use for feature extraction! ✓\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Test SimCLR trained model - extract features from sample patches\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models.resnet_simclr import ResNetSimCLR\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "CHECKPOINT_PATH = \"runs/Nov29_15-00-34_scc-214/checkpoints/model.pth\"\n",
    "TILES_DIR = \"/projectnb/ec500kb/projects/Project_1_Team_1/PANDA_DATA_MANNY/tiles_03\"\n",
    "NUM_TEST_PATCHES = 10  # Test on 10 random patches\n",
    "\n",
    "# ============================================================\n",
    "# LOAD MODEL\n",
    "# ============================================================\n",
    "def load_trained_model(checkpoint_path):\n",
    "    \"\"\"Load trained SimCLR model.\"\"\"\n",
    "    print(\"Loading trained SimCLR model...\")\n",
    "    \n",
    "    # Initialize model (same as training)\n",
    "    model = ResNetSimCLR(base_model=\"resnet18\", out_dim=512)\n",
    "    \n",
    "    # Load trained weights\n",
    "    state_dict = torch.load(checkpoint_path, map_location='cuda')\n",
    "    \n",
    "    # FIX: Remove 'module.' prefix from DataParallel\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] if k.startswith('module.') else k  # remove 'module.' prefix\n",
    "        new_state_dict[name] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    print(f\"✓ Model loaded from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE EXTRACTION\n",
    "# ============================================================\n",
    "def extract_features(model, image_path):\n",
    "    \"\"\"Extract 512-dim features from a patch.\"\"\"\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).cuda()  # Add batch dimension\n",
    "    \n",
    "    # Extract features (no gradients needed)\n",
    "    with torch.no_grad():\n",
    "        h, z = model(img_tensor)  # h = features, z = projections\n",
    "    \n",
    "    return h.cpu().numpy(), z.cpu().numpy()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TEST\n",
    "# ============================================================\n",
    "def test_model():\n",
    "    \"\"\"Test the trained model on sample patches.\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SIMCLR MODEL TEST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load model\n",
    "    model = load_trained_model(CHECKPOINT_PATH)\n",
    "    \n",
    "    # Get sample patches\n",
    "    print(f\"\\nFinding test patches in {TILES_DIR}...\")\n",
    "    all_patches = []\n",
    "    for wsi_dir in os.listdir(TILES_DIR):\n",
    "        wsi_path = os.path.join(TILES_DIR, wsi_dir)\n",
    "        if os.path.isdir(wsi_path):\n",
    "            patches = glob(os.path.join(wsi_path, \"*.jpeg\"))\n",
    "            all_patches.extend(patches)\n",
    "    \n",
    "    # Sample random patches\n",
    "    np.random.shuffle(all_patches)\n",
    "    test_patches = all_patches[:NUM_TEST_PATCHES]\n",
    "    \n",
    "    print(f\"✓ Found {len(all_patches)} total patches\")\n",
    "    print(f\"✓ Testing on {len(test_patches)} random patches\")\n",
    "    print()\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting features...\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    all_features = []\n",
    "    all_projections = []\n",
    "    \n",
    "    for i, patch_path in enumerate(test_patches):\n",
    "        patch_name = os.path.basename(patch_path)\n",
    "        \n",
    "        # Extract\n",
    "        features, projections = extract_features(model, patch_path)\n",
    "        all_features.append(features)\n",
    "        all_projections.append(projections)\n",
    "        \n",
    "        # Print stats\n",
    "        print(f\"[{i+1}/{len(test_patches)}] {patch_name}\")\n",
    "        print(f\"  Features shape:    {features.shape}\")\n",
    "        print(f\"  Projections shape: {projections.shape}\")\n",
    "        print(f\"  Feature norm:      {np.linalg.norm(features):.3f}\")\n",
    "        print(f\"  Feature mean:      {features.mean():.3f} ± {features.std():.3f}\")\n",
    "        print()\n",
    "    \n",
    "    # Convert to arrays\n",
    "    all_features = np.vstack(all_features)\n",
    "    all_projections = np.vstack(all_projections)\n",
    "    \n",
    "    # Analysis\n",
    "    print(\"=\"*70)\n",
    "    print(\"FEATURE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Features shape:    {all_features.shape}\")\n",
    "    print(f\"Projections shape: {all_projections.shape}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Feature statistics:\")\n",
    "    print(f\"  Mean:     {all_features.mean():.4f}\")\n",
    "    print(f\"  Std:      {all_features.std():.4f}\")\n",
    "    print(f\"  Min:      {all_features.min():.4f}\")\n",
    "    print(f\"  Max:      {all_features.max():.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Test similarity (patches should have diverse features)\n",
    "    print(\"Feature diversity check:\")\n",
    "    from scipy.spatial.distance import cosine\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(len(all_features)):\n",
    "        for j in range(i+1, len(all_features)):\n",
    "            sim = 1 - cosine(all_features[i], all_features[j])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    similarities = np.array(similarities)\n",
    "    print(f\"  Pairwise cosine similarity:\")\n",
    "    print(f\"    Mean: {similarities.mean():.3f}\")\n",
    "    print(f\"    Std:  {similarities.std():.3f}\")\n",
    "    print(f\"    Min:  {similarities.min():.3f}\")\n",
    "    print(f\"    Max:  {similarities.max():.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"=\"*70)\n",
    "    print(\"INTERPRETATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if similarities.mean() < 0.5:\n",
    "        print(\"✓ GOOD: Features are diverse (low similarity)\")\n",
    "        print(\"  → Model learned to distinguish different patches\")\n",
    "    elif similarities.mean() < 0.8:\n",
    "        print(\"✓ OK: Features have moderate diversity\")\n",
    "        print(\"  → Model provides useful representations\")\n",
    "    else:\n",
    "        print(\"⚠ WARNING: Features are very similar\")\n",
    "        print(\"  → Model may not have learned well\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Model is ready to use for feature extraction! ✓\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e1c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f25403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda_env",
   "language": "python",
   "name": "panda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
