{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4790e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PANDA DATASET DISTRIBUTION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Total: 10616 WSIs (Train: 8492, Val: 2124)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ISUP GRADE DISTRIBUTION\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ISUP   Train    Val      Total    %        Description\n",
      "----------------------------------------------------------------------\n",
      "0      2323     569      2892      27.2%   No cancer (Negative)\n",
      "1      2180     486      2666      25.1%   Benign / Low-grade (Gleason 3+3)*\n",
      "2      1074     269      1343      12.7%   Intermediate (Gleason 3+4)\n",
      "3      976      266      1242      11.7%   Intermediate (Gleason 4+3)\n",
      "4      997      252      1249      11.8%   High-grade (Gleason 4+4)\n",
      "5      942      282      1224      11.5%   High-grade (Gleason 4+5/5+4/5+5)\n",
      "\n",
      "*Note: ISUP 1 may represent low-grade cancerous tissue but is grouped\n",
      " as 'Benign' due to its indolent nature and favorable prognosis.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "3-CLASS MAPPING\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Class        ISUP       Train    Val      Total    %\n",
      "------------------------------------------------------------\n",
      "0 Background 0          2323     569      2892      27.2%\n",
      "1 Benign     1          2180     486      2666      25.1%\n",
      "2 Cancerous  2-5        3989     1069     5058      47.6%\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DATA PROVIDER DISTRIBUTION\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KAROLINSKA: 5456 WSIs (51.4%) - Train: 4375, Val: 1081\n",
      "  ISUP breakdown: ISUP 0: 1925, ISUP 1: 1814, ISUP 2: 668, ISUP 3: 317, ISUP 4: 481, ISUP 5: 251\n",
      "\n",
      "RADBOUD: 5160 WSIs (48.6%) - Train: 4117, Val: 1043\n",
      "  ISUP breakdown: ISUP 0: 967, ISUP 1: 852, ISUP 2: 675, ISUP 3: 925, ISUP 4: 768, ISUP 5: 973\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CLASS IMBALANCE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Imbalance ratio: 1.83:1 (largest class / smallest class)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAIN/VAL SPLIT CONSISTENCY\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Class           Train %    Val %      Diff\n",
      "---------------------------------------------\n",
      "0 Background    27.4%      26.8%      0.6% ✓\n",
      "1 Benign        25.7%      22.9%      2.8% ✓\n",
      "2 Cancerous     47.0%      50.3%      3.4% ⚠\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "PANDA Dataset Distribution Analysis\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_PATH = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/train_split.csv\"\n",
    "VAL_PATH = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/val_split.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "\n",
    "def map_3class(isup):\n",
    "    if isup == 0: return 0\n",
    "    elif isup == 1: return 1\n",
    "    else: return 2\n",
    "\n",
    "train_df['class_3'] = train_df['isup_grade'].apply(map_3class)\n",
    "val_df['class_3'] = val_df['isup_grade'].apply(map_3class)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PANDA DATASET DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTotal: {len(train_df) + len(val_df)} WSIs (Train: {len(train_df)}, Val: {len(val_df)})\")\n",
    "\n",
    "# ISUP Distribution\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ISUP GRADE DISTRIBUTION\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\n{'ISUP':<6} {'Train':<8} {'Val':<8} {'Total':<8} {'%':<8} {'Description'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "descriptions = {\n",
    "    0: \"No cancer (Negative)\",\n",
    "    1: \"Benign / Low-grade (Gleason 3+3)*\",\n",
    "    2: \"Intermediate (Gleason 3+4)\",\n",
    "    3: \"Intermediate (Gleason 4+3)\",\n",
    "    4: \"High-grade (Gleason 4+4)\",\n",
    "    5: \"High-grade (Gleason 4+5/5+4/5+5)\"\n",
    "}\n",
    "\n",
    "total = len(train_df) + len(val_df)\n",
    "for grade in range(6):\n",
    "    t = len(train_df[train_df['isup_grade'] == grade])\n",
    "    v = len(val_df[val_df['isup_grade'] == grade])\n",
    "    pct = (t + v) / total * 100\n",
    "    print(f\"{grade:<6} {t:<8} {v:<8} {t+v:<8} {pct:>5.1f}%   {descriptions[grade]}\")\n",
    "\n",
    "print(\"\\n*Note: ISUP 1 may represent low-grade cancerous tissue but is grouped\")\n",
    "print(\" as 'Benign' due to its indolent nature and favorable prognosis.\")\n",
    "\n",
    "# 3-Class Distribution\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"3-CLASS MAPPING\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\n{'Class':<12} {'ISUP':<10} {'Train':<8} {'Val':<8} {'Total':<8} {'%'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class_info = {\n",
    "    0: (\"Background\", \"0\"),\n",
    "    1: (\"Benign\", \"1\"),\n",
    "    2: (\"Cancerous\", \"2-5\")\n",
    "}\n",
    "\n",
    "for cls in range(3):\n",
    "    name, isup = class_info[cls]\n",
    "    t = len(train_df[train_df['class_3'] == cls])\n",
    "    v = len(val_df[val_df['class_3'] == cls])\n",
    "    pct = (t + v) / total * 100\n",
    "    print(f\"{cls} {name:<10} {isup:<10} {t:<8} {v:<8} {t+v:<8} {pct:>5.1f}%\")\n",
    "\n",
    "# Provider Analysis\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"DATA PROVIDER DISTRIBUTION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for provider in ['karolinska', 'radboud']:\n",
    "    t = len(train_df[train_df['data_provider'] == provider])\n",
    "    v = len(val_df[val_df['data_provider'] == provider])\n",
    "    pct = (t + v) / total * 100\n",
    "    print(f\"\\n{provider.upper()}: {t+v} WSIs ({pct:.1f}%) - Train: {t}, Val: {v}\")\n",
    "    \n",
    "    # ISUP breakdown per provider\n",
    "    print(f\"  ISUP breakdown: \", end=\"\")\n",
    "    combined = pd.concat([train_df, val_df])\n",
    "    provider_data = combined[combined['data_provider'] == provider]\n",
    "    isup_counts = provider_data['isup_grade'].value_counts().sort_index()\n",
    "    parts = [f\"ISUP {g}: {isup_counts.get(g, 0)}\" for g in range(6)]\n",
    "    print(\", \".join(parts))\n",
    "\n",
    "# Class Imbalance\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"CLASS IMBALANCE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "train_counts = train_df['class_3'].value_counts().sort_index()\n",
    "ratio = train_counts.max() / train_counts.min()\n",
    "print(f\"\\nImbalance ratio: {ratio:.2f}:1 (largest class / smallest class)\")\n",
    "\n",
    "# Train/Val Consistency\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TRAIN/VAL SPLIT CONSISTENCY\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\n{'Class':<15} {'Train %':<10} {'Val %':<10} {'Diff'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for cls in range(3):\n",
    "    t_pct = len(train_df[train_df['class_3'] == cls]) / len(train_df) * 100\n",
    "    v_pct = len(val_df[val_df['class_3'] == cls]) / len(val_df) * 100\n",
    "    diff = abs(t_pct - v_pct)\n",
    "    status = \"✓\" if diff < 3 else \"⚠\"\n",
    "    print(f\"{cls} {class_info[cls][0]:<12} {t_pct:>5.1f}%     {v_pct:>5.1f}%     {diff:>4.1f}% {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0421105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPLITTING VALIDATION INTO VAL + TEST\n",
      "============================================================\n",
      "\n",
      "Before split:\n",
      "  Train: 8492 (80.0%)\n",
      "  Val:   2124 (20.0%)\n",
      "\n",
      "After split:\n",
      "  Train: 8492 (80.0%)\n",
      "  Val:   1062 (10.0%)\n",
      "  Test:  1062 (10.0%)\n",
      "\n",
      "------------------------------------------------------------\n",
      "STRATIFICATION CHECK (ISUP Distribution)\n",
      "------------------------------------------------------------\n",
      "\n",
      "ISUP   Train %    Val %      Test %    \n",
      "----------------------------------------\n",
      "0        27.4%      26.7%      26.8%\n",
      "1        25.7%      22.9%      22.9%\n",
      "2        12.6%      12.7%      12.6%\n",
      "3        11.5%      12.5%      12.5%\n",
      "4        11.7%      11.9%      11.9%\n",
      "5        11.1%      13.3%      13.3%\n",
      "\n",
      "------------------------------------------------------------\n",
      "3-CLASS DISTRIBUTION\n",
      "------------------------------------------------------------\n",
      "\n",
      "Class        Train      Val        Test      \n",
      "---------------------------------------------\n",
      "0 Background 2323       284        285       \n",
      "1 Benign     2180       243        243       \n",
      "2 Cancerous  3989       535        534       \n",
      "\n",
      "------------------------------------------------------------\n",
      "FILES SAVED\n",
      "------------------------------------------------------------\n",
      "  /projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/val_split_new.csv  (1062 samples)\n",
      "  /projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/test_split.csv     (1062 samples)\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Final split:\n",
      "  Train: 8,492 WSIs (80%)  -> train_split.csv (unchanged)\n",
      "  Val:   1,062 WSIs (10%)  -> val_split_new.csv\n",
      "  Test:  1,062 WSIs (10%)  -> test_split.csv\n",
      "\n",
      "Total: 10,616 WSIs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Split validation set into validation and test sets\n",
    "Final split: 80% Train, 10% Val, 10% Test\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_PATH = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/train_split.csv\"\n",
    "VAL_PATH = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/val_split.csv\"\n",
    "OUTPUT_DIR = \"/projectnb/ec500kb/projects/Project_1_Team_1/Official_GTP_PANDAS/PANDAS/data/splits/\"\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLITTING VALIDATION INTO VAL + TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nBefore split:\")\n",
    "print(f\"  Train: {len(train_df)} ({len(train_df)/(len(train_df)+len(val_df))*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_df)} ({len(val_df)/(len(train_df)+len(val_df))*100:.1f}%)\")\n",
    "\n",
    "# Split validation 50/50 into new_val and test, stratified by isup_grade\n",
    "new_val_df, test_df = train_test_split(\n",
    "    val_df, \n",
    "    test_size=0.5, \n",
    "    random_state=42, \n",
    "    stratify=val_df['isup_grade']\n",
    ")\n",
    "\n",
    "total = len(train_df) + len(new_val_df) + len(test_df)\n",
    "\n",
    "print(f\"\\nAfter split:\")\n",
    "print(f\"  Train: {len(train_df)} ({len(train_df)/total*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(new_val_df)} ({len(new_val_df)/total*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df)} ({len(test_df)/total*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"STRATIFICATION CHECK (ISUP Distribution)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\n{'ISUP':<6} {'Train %':<10} {'Val %':<10} {'Test %':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for grade in range(6):\n",
    "    t_pct = len(train_df[train_df['isup_grade'] == grade]) / len(train_df) * 100\n",
    "    v_pct = len(new_val_df[new_val_df['isup_grade'] == grade]) / len(new_val_df) * 100\n",
    "    te_pct = len(test_df[test_df['isup_grade'] == grade]) / len(test_df) * 100\n",
    "    print(f\"{grade:<6} {t_pct:>6.1f}%    {v_pct:>6.1f}%    {te_pct:>6.1f}%\")\n",
    "\n",
    "# 3-class check\n",
    "def map_3class(isup):\n",
    "    if isup == 0: return 0\n",
    "    elif isup == 1: return 1\n",
    "    else: return 2\n",
    "\n",
    "train_df['class_3'] = train_df['isup_grade'].apply(map_3class)\n",
    "new_val_df['class_3'] = new_val_df['isup_grade'].apply(map_3class)\n",
    "test_df['class_3'] = test_df['isup_grade'].apply(map_3class)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"3-CLASS DISTRIBUTION\")\n",
    "print(\"-\" * 60)\n",
    "class_names = {0: \"Background\", 1: \"Benign\", 2: \"Cancerous\"}\n",
    "print(f\"\\n{'Class':<12} {'Train':<10} {'Val':<10} {'Test':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for cls in range(3):\n",
    "    t = len(train_df[train_df['class_3'] == cls])\n",
    "    v = len(new_val_df[new_val_df['class_3'] == cls])\n",
    "    te = len(test_df[test_df['class_3'] == cls])\n",
    "    print(f\"{cls} {class_names[cls]:<10} {t:<10} {v:<10} {te:<10}\")\n",
    "\n",
    "# Save new splits\n",
    "new_val_df.drop(columns=['class_3'], inplace=True)\n",
    "test_df.drop(columns=['class_3'], inplace=True)\n",
    "\n",
    "new_val_df.to_csv(OUTPUT_DIR + \"val_split_new.csv\", index=False)\n",
    "test_df.to_csv(OUTPUT_DIR + \"test_split.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"FILES SAVED\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  {OUTPUT_DIR}val_split_new.csv  ({len(new_val_df)} samples)\")\n",
    "print(f\"  {OUTPUT_DIR}test_split.csv     ({len(test_df)} samples)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "Final split:\n",
    "  Train: {len(train_df):,} WSIs (80%)  -> train_split.csv (unchanged)\n",
    "  Val:   {len(new_val_df):,} WSIs (10%)  -> val_split_new.csv\n",
    "  Test:  {len(test_df):,} WSIs (10%)  -> test_split.csv\n",
    "\n",
    "Total: {total:,} WSIs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd7cdc",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "As shown, we split the data into 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c65de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda_env",
   "language": "python",
   "name": "panda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
